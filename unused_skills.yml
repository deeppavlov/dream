services:
  aiml:
    build:
      args:
        skill_endpoint: aiml
        skillconfig: skills/aiml/aiml_skill.json
        skillhost: 0.0.0.0
        skillport: 2080
      context: ./
      dockerfile: dp/dockerfile_skill_cpu
    environment:
      - CUDA_VISIBLE_DEVICES=""
    ports:
      - 2080:2080
  transfertransfo:
    build:
      context: ./skills/transfertransfo/
    environment:
      DEVICE: cuda
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8007 -t 60
    volumes: []
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu == true
  retrieval_chitchat:
    build:
      context: ./skills/retrieval_chitchat/
    command: uvicorn server:app --host 0.0.0.0 --port 8015
    volumes: []
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu != true
  convert_reddit_with_personality:
    build:
      context: ./skills/convert_reddit_with_personality/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8048 -t 60
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  news_skill:
    build:
      context: .
      dockerfile: ./skills/alexa-prize-news/Dockerfile
    command: bash -c "python updater.py | gunicorn --workers=1 server:app -b 0.0.0.0:8027 -t 300"
    volumes: []
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu != true
  topicalchat_convert_retrieval:
    build:
      context: ./skills/topicalchat_convert_retrieval/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8060 -t 60
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
          - node.labels.group == 0
  reddit_ner_skill:
    build:
      context: .
      dockerfile: ./skills/reddit_ner_skill/Dockerfile
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8035
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  book_skill:
    build:
      context: .
      dockerfile: ./skills/book_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8032
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  question-generator:
    build:
      context: ./services/question_generator/
      args:
        MODEL_URL: http://lnsigo.mipt.ru/export/alexaprize_data/question_generator/model_24_0.94_37.23.pth
    command: gunicorn --workers=1 --timeout 300 server:app -b 0.0.0.0:8079
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DECODING=greedy
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G
version: '3.7'
