services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run -ch http_client -pl assistant_dists/dream_russian/pipeline_conf.json --cors'
    environment:
      WAIT_HOSTS: "dff-program-y-skill:8008, convers-evaluation-selector:8009, 
          dff-intent-responder-skill:8012, intent-catcher:8014, badlisted-words:8018,
          ner:8021, personal-info-skill:8030, sentseg:8011,
          spelling-preprocessing:8074, entity-linking:8075, wiki-parser:8077, dff-generative-skill:8092,
          dff-friendship-skill:8086, dff-wiki-skill:8111, entity-detection:8103, dialogpt:8091,
          dff-template-skill:8120, spacy-annotator:8125"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-480}

  dff-program-y-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8008
        SERVICE_NAME: dff_program_y_skill
        LANGUAGE: RU
      context: .
      dockerfile: ./skills/dff_program_y_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8008 --reload
    deploy:
      resources:
        limits:
          memory: 1024M
        reservations:
          memory: 1024M

  convers-evaluation-selector:
    env_file: [.env]
    build:
      context: .
      dockerfile: ./response_selectors/convers_evaluation_based_selector/Dockerfile
      args:
        LANGUAGE: RU
    command: flask run -h 0.0.0.0 -p 8009
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dff-intent-responder-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8012
        SERVICE_NAME: dff_intent_responder_skill
        INTENT_RESPONSE_PHRASES_FNAME: intent_response_phrases_RU.json
      context: .
      dockerfile: ./skills/dff_intent_responder_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8012 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  sentseg:
    env_file: [.env]
    build:
      args:
        CONFIG: sentseg_ru_bert_torch.json
      context: ./annotators/sentseg_ru
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 500M
        reservations:
          memory: 500M

  intent-catcher:
    env_file: [.env]
    build:
      context: ./annotators/IntentCatcher/
      args:
        INTENT_MODEL_FNAME: linear_classifier_h3_RU.h5
        USE_MODEL_PATH: https://tfhub.dev/google/universal-sentence-encoder-multilingual/1
        INTENT_DATA_FNAME: intent_data_h3_RU.json
        INTENT_PHRASES_FNAME: intent_phrases_RU.json
        LANGUAGE: RU
    command:  python -m flask run -h 0.0.0.0 -p 8014 --without-threads
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  badlisted-words:
    env_file: [.env]
    build:
      args:
        LANGUAGE: RU
      context: annotators/BadlistedWordsDetector/
    command: flask run -h 0.0.0.0 -p 8018
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  ner:
    env_file: [.env]
    build:
      args:
        CONFIG: ner_uncased_rus_bert_torch.json
        PORT: 8021
        SRC_DIR: annotators/NER_ru
        COMMIT: f5117cd9ad1e64f6c2d970ecaa42fc09ccb23144
        LANGUAGE: RU
      context: ./
      dockerfile: annotators/NER_ru/Dockerfile
    command: flask run -h 0.0.0.0 -p 8021
    environment:
      - FLASK_APP=server
    tty: true
    deploy:
      resources:
        limits:
          memory: 1512M
        reservations:
          memory: 1512M
  
  entity-detection:
    env_file: [.env]
    build:
      args:
        CONFIG: entity_detection_rus.json
        PORT: 8103
        SRC_DIR: annotators/entity_detection_rus
        LANGUAGE: RU
      context: ./
      dockerfile: annotators/entity_detection_rus/Dockerfile
    command: flask run -h 0.0.0.0 -p 8103
    environment:
      - FLASK_APP=server
    tty: true
    deploy:
      resources:
        limits:
          memory: 1512M
        reservations:
          memory: 1512M

  personal-info-skill:
    env_file: [.env]
    build:
      context: .
      dockerfile: ./skills/personal_info_skill/Dockerfile
      args:
        LANGUAGE: RU
    command: flask run -h 0.0.0.0 -p 8030
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  entity-linking:
    env_file: [.env]
    build:
      args:
        CONFIG: entity_linking_rus.json
        PORT: 8075
        SRC_DIR: annotators/entity_linking_rus
        LANGUAGE: RU
      context: ./
      dockerfile: annotators/entity_linking_rus/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  wiki-parser:
    env_file: [.env]
    build:
      args:
        WIKI_LITE_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata_lite.hdt
        WIKI_LITE_INDEX_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata_lite.hdt.index.v1-1
        WIKI_CACHE_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata_cache.json
        CONFIG: wiki_parser.json
        PORT: 8077
        SRC_DIR: annotators/wiki_parser
        COMMIT: ff5b156d16a949c3ec99da7fb60ae907dec37a41
        LANGUAGE: RU
      context: ./
      dockerfile: annotators/wiki_parser/Dockerfile
    command: flask run -h 0.0.0.0 -p 8077
    environment:
      - CUDA_VISIBLE_DEVICES=''
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  spelling-preprocessing:
    env_file: [.env]
    build:
      args:
        CONFIG: levenshtein_corrector_ru.json
        PORT: 8074
        SRC_DIR: annotators/spelling_preprocessing_ru
        COMMIT: f5117cd9ad1e64f6c2d970ecaa42fc09ccb23144
        LANGUAGE: RU
      context: ./
      dockerfile: annotators/spelling_preprocessing_ru/Dockerfile
    command: flask run -h 0.0.0.0 -p 8074
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  spacy-annotator:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8125
        SRC_DIR: annotators/spacy_annotator
        SPACY_MODEL: ru_core_news_sm
        TOKEN_ATTRIBUTES: pos_|dep_|lemma_|ent_iob_|ent_type_|morph
      context: ./
      dockerfile: annotators/spacy_annotator/Dockerfile
    command: flask run -h 0.0.0.0 -p 8125
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-friendship-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8086
        SERVICE_NAME: dff_friendship_skill # has to be the same with skill dir name
        LANGUAGE: RU
      context: .
      dockerfile: ./skills/dff_friendship_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8086
    # command:  flask run -h 0.0.0.0 -p 8086
    # environment:
    #   - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dff-wiki-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8111
        SERVICE_NAME: dff_wiki_skill
        COMMIT: 5b99ac3392e8e178e2bb4f9b218d4ddb2ec2e242
        LANGUAGE: RU
      context: ./
      dockerfile: ./skills/dff_wiki_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8111
    # command:  flask run -h 0.0.0.0 -p 8111
    # environment:
    #   - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dialogpt:
    env_file: [ .env ]
    build:
      context: ./services/dialogpt_RU/
      args:
        SERVICE_PORT: 8091
        PRETRAINED_MODEL_NAME_OR_PATH: "Grossmend/rudialogpt3_medium_based_on_gpt2"
        LANGUAGE: RU
    command: flask run -h 0.0.0.0 -p 8091
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 2.5G

  dff-generative-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8092
        SERVICE_NAME: dff_generative_skill
        LANGUAGE: RU
      context: .
      dockerfile: ./skills/dff_generative_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8092 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dialogrpt:
    env_file: [ .env ]
    build:
      context: ./services/dialogrpt_ru/
      args:
        SERVICE_PORT: 8122
        PRETRAINED_MODEL_FNAME: dialogrpt_ru_ckpt_v0.pth
        TOKENIZER_NAME_OR_PATH: "Grossmend/rudialogpt3_medium_based_on_gpt2"
    command: flask run -h 0.0.0.0 -p 8122
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 2.5G

  dff-template-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8120
        SERVICE_NAME: dff_template_skill
      context: .
      dockerfile: ./skills/dff_template_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8120 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

version: '3.7'
